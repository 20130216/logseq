## ğŸ”– æ–‡ç« 
	- [Omnivore å…¥é—¨ --- Getting Started with Omnivore](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2)
	  collapsed:: true
	  site:: [Omnivore](https://omnivore.app/zhangxinxin0216/getting-started-with-omnivore)
	  author:: unknown
	  labels:: [[æ’ä»¶ç±»]]
	  date-saved:: [[Aug 23rd, 2024]]
		- ### é«˜äº®
		  collapsed:: true
			- > * Saving å‚¨è“„
			  * Reading è¯»æ•°
			  * Organizing ç»„ç»‡
			  * Integrations é›†æˆ [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#ce4b3b05-d311-4b9e-bdcc-462d6d7496e6)
			- > **å›¾ä¹¦é¦†**æ˜¯æ‚¨ Omnivore ä½“éªŒçš„ä¸­å¿ƒ [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#843cb26a-b673-4a42-afe2-7341c64a2343)
			- > ä» Mac å­˜å‚¨ PDF [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#81e8fe5b-a27c-4e36-a2cb-7900a36c1731)
	- [The Secret Power of â€˜Read It Laterâ€™ Appsï¼ˆã€Šå“ˆä½›å•†ä¸šè¯„è®ºã€‹æœ€è¿‘å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« ä¸ºè¿™ç§æ–°çš„ç¥ç»ç°è±¡å‘½åï¼šæ³¨æ„åŠ›ç¼ºé™·ç‰¹è´¨ï¼‰](https://omnivore.app/me/the-secret-power-of-read-it-later-apps)
	  collapsed:: true
	  site:: [Forte Labs](https://fortelabs.co/blog/the-secret-power-of-read-it-later-apps)
	  author:: Tiago Forte
	  labels:: [[æ’ä»¶ç±»]]
	  date-saved:: [[Aug 21st, 2024]]
	  date-published:: [[Jan 24th, 2022]]
		- ### é«˜äº®
		  collapsed:: true
			- > å®‰é™åœ°åç€å¹¶æŒç»­å¼•å¯¼é›†ä¸­æ³¨æ„åŠ› [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#577a975d-2a51-4b1b-a893-c61a00af33e7)
			- > å˜å¾—æå…¶ç¨€ç¼º [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#e00eb005-313c-46a5-9e06-252e66166db0)
			- > é˜…è¯»èƒ½åŠ›æ­£åœ¨æˆä¸ºä¸–ç•Œç«äº‰ä¼˜åŠ¿çš„æºæ³‰ [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#fb149552-6d21-4a21-ba8a-49f7f4a89337)
			- > æ³¨æ„åŠ› [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#685878d3-c8d7-4f52-a0c9-16bfdac4ee12)
			- > ï¼šæ³¨æ„åŠ›ç¼ºé™·ç‰¹è´¨ [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#ac3cc662-2b2f-4ddd-a8bb-bcd2108e298a)
			- > ã€Šå“ˆä½›å•†ä¸šè¯„è®ºã€‹ [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#1f16f434-4adb-49c7-a772-8556d1c95c23)
			- > åˆ†å¿ƒã€å†…å¿ƒç‹‚çƒ­å’Œä¸è€çƒ¦ [â¤´ï¸](https://omnivore.app/me/the-secret-power-of-read-it-later-apps#70ed8da2-246a-4e77-9a0b-8f7312a3ee5e)
	- [æ–‡å¿ƒä¸€è¨€](https://omnivore.app/me/-1917df2e673)
	  collapsed:: true
	  site:: [yiyan.baidu.com](https://yiyan.baidu.com/chat/4524638783)
	  author:: unknown
	  labels:: [[æ–‡å¿ƒä¸€è¨€]]
	  date-saved:: [[Aug 23rd, 2024]]
		- ### é«˜äº®
		  collapsed:: true
			- > API Endpointè¿˜å¯ä»¥ä¸å®‰å…¨æ€§æªæ–½å’Œæƒé™æ§åˆ¶æœºåˆ¶ç›¸ç»“åˆï¼Œä»¥ç¡®ä¿åªæœ‰å…·æœ‰é€‚å½“æƒé™çš„å®¢æˆ·ç«¯æ‰èƒ½è®¿é—®ç‰¹å®šçš„èµ„æºã€‚è¿™æœ‰åŠ©äºä¿æŠ¤APIçš„æ•æ„Ÿæ•°æ®å’ŒåŠŸèƒ½ä¸è¢«æœªç»æˆæƒçš„è®¿é—®ã€‚ [â¤´ï¸](https://omnivore.app/me/-1917df2e673#39f3afa6-e654-4144-ac0f-e7b529fbfbd2)
	- [å¼€æºRAGæ¡†æ¶æ±‡æ€»-CSDNåšå®¢](https://omnivore.app/me/rag-csdn-1917dcec1e0) 
	  site:: [blog.csdn.net](https://blog.csdn.net/qq_33137873/article/details/138683590?depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%257Edefault%257EBlogCommendFromBaidu%257ERate-1-138683590-blog-141191700.235%255Ev43%255Epc_blog_bottom_relevance_base9&spm=1001.2101.3001.6650.1)
	  author:: æˆå°±ä¸€äº¿æŠ€æœ¯äºº!
	  labels:: [[CSDN]] [[RAG]]
	  date-saved:: [[Aug 23rd, 2024]]
	  date-published:: [[May 18th, 2024]]
		- ### é«˜äº®
		  collapsed:: true
			- > FastGPT [â¤´ï¸](https://omnivore.app/me/rag-csdn-1917dcec1e0#bf4a66fa-a853-47e9-ab6c-463eecb239b7)
			- > QAnything [â¤´ï¸](https://omnivore.app/me/rag-csdn-1917dcec1e0#88f30683-b772-4470-8478-7a4154721127)
			- > open-webui [â¤´ï¸](https://omnivore.app/me/rag-csdn-1917dcec1e0#bef7bed8-0d53-4e52-affe-85ab9a72f42f)
			- > RAGFlow [â¤´ï¸](https://omnivore.app/me/rag-csdn-1917dcec1e0#a9da2136-4c30-4cee-9fd0-046ef37b670a)
	- [Qwen2 -å¾®è°ƒ Qwen2_qwen2 å¾®è°ƒ-CSDNåšå®¢](https://omnivore.app/me/qwen-2-qwen-2-qwen-2-csdn-1917d392cab)
	  collapsed:: true
	  site:: [blog.csdn.net](https://blog.csdn.net/sinat_37574187/article/details/140603260?biz_id=0&ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522172438273216800185884936%252522%25252C%252522scm%252522%25253A%25252220140713.130102334.pc%25255Fall.%252522%25257D&request_id=172438273216800185884936&spm=1018.2226.3001.4187)
	  author:: æˆå°±ä¸€äº¿æŠ€æœ¯äºº!
	  labels:: [[CSDN]] [[å¤§æ¨¡å‹/å¾®è°ƒ]]
	  date-saved:: [[Aug 23rd, 2024]]
	  date-published:: [[Jul 22nd, 2024]]
		- [![ä¸¹åŠªä»€Â·åº“é©¬å°”](https://img-blog.csdnimg.cn/img_convert/6eea6312bd3a8f0afa43f01afed5362e.jpeg)](https://medium.com/@danushidk507?source=post%5Fpage-----f89c5c9d15da--------------------------------)
		- é˜…è¯»æ—¶é—´ï¼š7 åˆ†é’Ÿ 2024 å¹´ 6 æœˆ 8 æ—¥
		- é˜¿é‡Œäº‘æœ€æ–°ç³»åˆ—è¯­è¨€æ¨¡å‹ç”±äºæ€§èƒ½æå‡å’Œå®‰å…¨åŠŸèƒ½å¢å¼ºï¼Œäºå‘¨äº”æ¨å‡ºåè¿…é€Ÿè·ƒå±…å¼€æº LLM æ’è¡Œæ¦œé¦–ä½ã€‚
		- Qwen2 ç³»åˆ—åŒ…æ‹¬å„ç§åŸºç¡€è¯­è¨€æ¨¡å‹å’ŒæŒ‡ä»¤è°ƒæ•´è¯­è¨€æ¨¡å‹ï¼Œå¤§å°ä» 0.5 åˆ° 720 äº¿ä¸ªå‚æ•°ï¼Œä»¥åŠæ··åˆä¸“å®¶ (MoE) æ¨¡å‹ã€‚
		- è¿™äº›æ›´æ–°çš„åŠŸèƒ½ä½¿å…¶åœ¨åä½œäººå·¥æ™ºèƒ½å¹³å° Hugging Face çš„ Open LLM Leaderboard ä¸Šå æ®é¦–ä½ï¼Œå¯ç”¨äºå•†ä¸šæˆ–ç ”ç©¶æ´»åŠ¨ã€‚
		- ![](https://img-blog.csdnimg.cn/img_convert/32c4169b9b8d467745a2224cab6def6a.jpeg)
		- ä¸­å›½ç”µå•†å·¨å¤´é˜¿é‡Œå·´å·´åœ¨ä¸­å›½äººå·¥æ™ºèƒ½é¢†åŸŸå æœ‰é‡è¦åœ°ä½ã€‚ä»Šå¤©ï¼Œé˜¿é‡Œå·´å·´å‘å¸ƒäº†æœ€æ–°çš„äººå·¥æ™ºèƒ½æ¨¡å‹ Qwen2ï¼Œè¯¥æ¨¡å‹è¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€å¥½çš„å¼€æºæ¨¡å‹ä¹‹ä¸€ã€‚
		- Qwen2 ç”±é˜¿é‡Œäº‘å¼€å‘ï¼Œä»£è¡¨äº†è¯¥å…¬å¸ç»Ÿä¸€åƒæ–‡ï¼ˆQwenï¼‰æ¨¡å‹ç³»åˆ—çš„ä¸‹ä¸€é˜¶æ®µï¼Œè¯¥ç³»åˆ—åŒ…æ‹¬ç»Ÿä¸€åƒæ–‡ LLMï¼ˆQwenï¼‰ã€è§†è§‰ AI æ¨¡å‹ Qwen-VL å’Œ Qwen-Audioã€‚
		- Qwen æ¨¡å‹ç³»åˆ—å·²é’ˆå¯¹ä¸åŒè¡Œä¸šå’Œé¢†åŸŸçš„å¤šè¯­è¨€æ•°æ®è¿›è¡Œäº†é¢„è®­ç»ƒï¼Œå…¶ä¸­ Qwen-72B æ˜¯è¯¥ç³»åˆ—ä¸­æœ€å¼ºå¤§çš„æ¨¡å‹ã€‚è¯¥æ¨¡å‹å·²é’ˆå¯¹æƒŠäººçš„ 3 ä¸‡äº¿ä¸ª token æ•°æ®è¿›è¡Œäº†è®­ç»ƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMeta æœ€å¼ºå¤§çš„ Llama-2 å˜ä½“åŸºäº 2 ä¸‡äº¿ä¸ª token æ„å»ºã€‚ä¸æ­¤åŒæ—¶ï¼ŒLlama-3 ç›®å‰æ­£åœ¨å¤„ç† 15 ä¸‡äº¿ä¸ª tokenã€‚
		- ## æ¨¡å‹è¯¦ç»†ä¿¡æ¯
		- Qwen2 æ˜¯ä¸€ç³»åˆ—è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬å„ç§å¤§å°çš„è§£ç å™¨æ¨¡å‹ã€‚é˜¿é‡Œå·´å·´å·²é’ˆå¯¹æ¯ç§å¤§å°å‘å¸ƒäº†åŸºç¡€è¯­è¨€æ¨¡å‹å’Œå¯¹é½èŠå¤©æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åŸºäº Transformer æ¶æ„æ„å»ºï¼Œå…·æœ‰ SwiGLU æ¿€æ´»ã€æ³¨æ„ QKV åå·®ã€ç»„æŸ¥è¯¢æ³¨æ„ã€æ»‘åŠ¨çª—å£æ³¨æ„å’Œå…¨æ³¨æ„çš„æ··åˆç­‰åŠŸèƒ½ã€‚æ­¤å¤–ï¼Œé˜¿é‡Œå·´å·´è¿˜å¼€å‘äº†ä¸€ç§å¢å¼ºçš„æ ‡è®°å™¨ï¼Œå¯é€‚åº”å¤šç§è‡ªç„¶è¯­è¨€å’Œä»£ç ã€‚
		- * å‹å·å°ºå¯¸ï¼šQwen2â€“0.5Bã€Qwen2â€“1.5Bã€Qwen2â€“7Bã€Qwen2â€“57B-A14B å’Œ Qwen2â€“72Bï¼›
		- * é™¤äº†è‹±è¯­å’Œä¸­æ–‡ä¹‹å¤–ï¼Œè¿˜ä½¿ç”¨äº† 27 ç§è¯­è¨€çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼›
		- * å„é¡¹åŸºå‡†æµ‹è¯•ä¸­å–å¾—ä¼˜å¼‚æˆç»©ï¼›
		- * å¢å¼ºç¼–ç å’Œæ•°å­¦èƒ½åŠ›ï¼›
		- * ä½¿ç”¨ Qwen2-7B å°†ä¸Šä¸‹æ–‡é•¿åº¦æ”¯æŒæ‰©å±•åˆ° 128K ä¸ªæ ‡è®°
		- * Instruct å’Œ Qwen2â€“72B-Instructã€‚
		- ## æ¨¡å‹ä¿¡æ¯
		- Qwen2 ç³»åˆ—ç”± 5 ç§å°ºå¯¸çš„åŸºç¡€å’ŒæŒ‡ä»¤è°ƒæ•´æ¨¡å‹ç»„æˆï¼šQwen2â€“0.5Bã€Qwen2â€“1.5Bã€Qwen2â€“7Bã€Qwen2â€“57B-A14B å’Œ Qwen2â€“72Bã€‚ä¸‹è¡¨è¯¦ç»†ä»‹ç»äº†è¿™äº›æ¨¡å‹çš„åŸºæœ¬ä¿¡æ¯ï¼š
		- ![](https://img-blog.csdnimg.cn/img_convert/50414b4d6b2131aa17754e73a855bf5a.png)
		- ## è¡¨ç°
		- å¯¹æ¯”è¯„ä¼°æ˜¾ç¤ºï¼Œå¤§è§„æ¨¡æ¨¡å‹ï¼ˆ70B+å‚æ•°ï¼‰ç›¸æ¯”Qwen1.5æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æœ¬ç ”ç©¶é‡ç‚¹è¯„ä¼°å¤§è§„æ¨¡æ¨¡å‹Qwen2â€“72Bçš„æ€§èƒ½ï¼Œä»è‡ªç„¶è¯­è¨€ç†è§£ã€çŸ¥è¯†è·å–ã€ç¼–ç èƒ½åŠ›ã€æ•°å­¦èƒ½åŠ›ã€å¤šè¯­è¨€èƒ½åŠ›ç­‰å¤šä¸ªæ–¹é¢å¯¹Qwen2â€“72Bä¸å‰æ²¿å¼€æ”¾æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚å¾—ç›Šäºç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®é›†å’Œç²¾æ¹›çš„è®­ç»ƒæŠ€å·§ï¼ŒQwen2â€“72Båœ¨ä¸Llama-3â€“70Bç­‰é¡¶çº§æ¨¡å‹çš„å¯¹å†³ä¸­å±•ç°å‡ºä¼˜å¼‚çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨å‚æ•°è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œå…¶æ€§èƒ½è¡¨ç°ä¼˜äºä¸Šä¸€ä»£Qwen1.5â€“110Bã€‚
		- ![](https://img-blog.csdnimg.cn/img_convert/4a150140159a51d02bc3e2beadfddbfb.jpeg)
		- ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">ä» transformers å¯¼å…¥ AutoModelForCausalLMã€AutoTokenizer
		  - device = <span style="color:#c41a16">"cuda" </span> <span style="color:#007400"># å°†æ¨¡å‹åŠ è½½åˆ°çš„è®¾å¤‡</span>
		  - model = AutoModelForCausalLM.from_pretrained( <span style="color:#c41a16">"Qwen/Qwen1.5-7B-Chat"</span> , device_map= <span style="color:#c41a16">"auto"</span> )
		  - tokenizer = AutoTokenizer.from_pretrained( <span style="color:#c41a16">"Qwen/Qwen1.5-7B-Chat"</span> )
		  - prompt = <span style="color:#c41a16">"è¯·ç®€å•ä»‹ç»ä¸€ä¸‹å¤§å‹è¯­è¨€æ¨¡å‹ã€‚"</span>
		  - æ¶ˆæ¯ = [{ <span style="color:#c41a16">â€œè§’è‰²â€</span>ï¼š<span style="color:#c41a16">â€œç”¨æˆ·â€</span>ï¼Œ<span style="color:#c41a16">â€œå†…å®¹â€</span>ï¼šæç¤º}]
		  - æ–‡æœ¬ = tokenizer.apply_chat_templateï¼ˆæ¶ˆæ¯ï¼Œtokenize = Falseï¼Œadd_generation_prompt = Trueï¼‰
		  - model_inputs = tokenizerï¼ˆ[text]ï¼Œreturn_tensors = <span style="color:#c41a16">â€œptâ€</span>ï¼‰ã€‚åˆ°ï¼ˆè®¾å¤‡ï¼‰
		  - generated_ids = model.generateï¼ˆmodel_inputs.input_idsï¼Œmax_new_tokens = 512ï¼Œdo_sample = Trueï¼‰
		  - generated_ids = [output_ids [lenï¼ˆinput_idsï¼‰ï¼š] for input_idsï¼Œoutput_ids in zipï¼ˆmodel_inputs.input_idsï¼Œgenerated_idsï¼‰]
		  - å“åº” = tokenizer.batch_decodeï¼ˆgenerated_idsï¼Œskip_special_tokens = Trueï¼‰[0]</span></span>
		  - ```
		  - ### Qwen2Config
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">ï¼ˆvocab_size = <span style="color:#1c00cf">151936</span> hidden_â€‹â€‹size = <span style="color:#1c00cf">4096i</span> ntermied_size = <span style="color:#1c00cf">22016</span> num_hidden_â€‹â€‹layers = <span style="color:#1c00cf">32</span> num_attention_heads = <span style="color:#1c00cf">32</span> num_key_value_heads = <span style="color:#1c00cf">32</span> hidden_â€‹â€‹act = <span style="color:#c41a16">'silu'</span> max_position_embeddings = <span style="color:#1c00cf">32768i</span> nitializer_range = <span style="color:#1c00cf">0.02</span> rms_norm_eps = <span style="color:#1c00cf">1e-06</span> use_cache = Truetie_word_embeddings = Falserope_theta = <span style="color:#1c00cf">10000.0</span> use_sliding_window = Falsesliding_window = <span style="color:#1c00cf">4096</span> max_window_layers = <span style="color:#1c00cf">28tention_dropout</span> = <span style="color:#1c00cf">0.0</span> **kwargsï¼‰</span></span>
		  - ```
		  - **å‚æ•°**
		  - * vocab\_sizeï¼ˆ`int`ï¼Œ_å¯é€‰ï¼Œé»˜è®¤ä¸º 151936ï¼‰â€” Qwen2 æ¨¡å‹çš„è¯æ±‡é‡ã€‚å®šä¹‰è°ƒç”¨_[Qwen2Model](https://huggingface.co/docs/transformers/v4.41.3/en/model%5Fdoc/qwen2#transformers.Qwen2Model)`inputs_ids`æ—¶ä¼ é€’çš„å¯ä»¥è¡¨ç¤ºçš„ä¸åŒæ ‡è®°çš„æ•°é‡
		  - * hidden\_â€‹â€‹size ï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 4096ï¼‰â€” éšè—è¡¨ç¤ºçš„ç»´åº¦ã€‚
		  - * middle\_sizeï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 22016ï¼‰â€” MLP è¡¨ç¤ºçš„ç»´åº¦ã€‚
		  - * num\_hidden\_â€‹â€‹layersï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 32ï¼‰â€” Transformer ç¼–ç å™¨ä¸­çš„éšè—å±‚çš„æ•°é‡ã€‚
		  - * num\_attention\_headsï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 32ï¼‰â€” Transformer ç¼–ç å™¨ä¸­æ¯ä¸ªæ³¨æ„å±‚çš„æ³¨æ„å¤´çš„æ•°é‡ã€‚
		  - * num\_key\_value\_headsï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 32ï¼‰â€” è¿™æ˜¯åº”ç”¨äºå®ç°åˆ†ç»„æŸ¥è¯¢æ³¨æ„çš„ key\_value å¤´çš„æ•°é‡ã€‚å¦‚æœä¸º`num_key_value_heads=num_attention_heads`ï¼Œåˆ™æ¨¡å‹å°†ä½¿ç”¨å¤šå¤´æ³¨æ„ (MHA)ï¼Œå¦‚æœä¸º`num_key_value_heads=1 the model will use Multi Query Attention (MQA) otherwise GQA is used. When converting a multi-head checkpoint to a GQA checkpoint, each group key and value head should be constructed by meanpooling all the original heads within that group. For more details checkout [this paper](https://arxiv.org/pdf/2305.13245.pdf). If it is not specified, will default to `32\`ã€‚
		  - * hidden\_â€‹â€‹act ï¼ˆ`str`æˆ–`function`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º`"silu"`ï¼‰â€”â€”è§£ç å™¨ä¸­çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå‡½æ•°æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚
		  - * max\_position\_embeddingsï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 32768ï¼‰â€”â€”æ­¤æ¨¡å‹å¯èƒ½ä½¿ç”¨çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚
		  - * initializer\_rangeï¼ˆ`float`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 0.02ï¼‰â€” ç”¨äºåˆå§‹åŒ–æ‰€æœ‰æƒé‡çŸ©é˜µçš„ truncated\_normal\_initializer çš„æ ‡å‡†å·®ã€‚
		  - * rms\_norm\_eps ï¼ˆ`float`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 1e-06ï¼‰â€” rms æ ‡å‡†åŒ–å±‚ä½¿ç”¨çš„ epsilonã€‚
		  - * use\_cache ( `bool`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º`True`) â€” æ¨¡å‹æ˜¯å¦åº”è¿”å›æœ€åçš„é”®/å€¼æ³¨æ„ï¼ˆå¹¶éæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ï¼‰ã€‚ä»…åœ¨ æ—¶ç›¸å…³`config.is_decoder=True`ã€‚
		  - * tie\_word\_embeddings ï¼ˆ`bool`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º`False`ï¼‰ - æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºè¯åµŒå…¥æ˜¯å¦åº”è¯¥ç»‘å®šã€‚
		  - * rope\_thetaï¼ˆ`float`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 10000.0ï¼‰â€” RoPE åµŒå…¥çš„åŸºå‡†å‘¨æœŸã€‚
		  - * use\_sliding\_windowï¼ˆ`bool`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º`False`ï¼‰â€”æ˜¯å¦ä½¿ç”¨æ»‘åŠ¨çª—å£æ³¨æ„åŠ›ã€‚
		  - * slider\_windowï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 4096ï¼‰â€” æ»‘åŠ¨çª—å£æ³¨æ„ (SWA) çª—å£å¤§å°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™é»˜è®¤ä¸º`4096`ã€‚
		  - * max\_window\_layersï¼ˆ`int`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 28ï¼‰â€” ä½¿ç”¨ SWAï¼ˆæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼‰çš„å±‚æ•°ã€‚åº•å±‚ä½¿ç”¨ SWAï¼Œé¡¶å±‚ä½¿ç”¨å®Œå…¨æ³¨æ„åŠ›ã€‚
		  - * tention\_dropout ï¼ˆ`float`ï¼Œ_å¯é€‰_ï¼Œé»˜è®¤ä¸º 0.0ï¼‰â€” æ³¨æ„æ¦‚ç‡çš„ä¸¢å¤±ç‡ã€‚
		  - ### Ollama â€” Qwen2
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">ollama serve
		  - <span style="color:#007400"># ä½ éœ€è¦åœ¨ä½¿ç”¨ ollama æ—¶ä¿æŒæ­¤æœåŠ¡è¿è¡Œ</span></span></span>
		  - ```
		  - è¦æå–æ¨¡å‹æ£€æŸ¥ç‚¹å¹¶è¿è¡Œæ¨¡å‹ï¼Œè¯·ä½¿ç”¨è¯¥`ollama run`å‘½ä»¤ã€‚æ‚¨å¯ä»¥é€šè¿‡åœ¨ åæ·»åŠ åç¼€æ¥æŒ‡å®šæ¨¡å‹å¤§å°`qwen2`ï¼Œä¾‹å¦‚`:0.5b`ã€`:1.5b`ã€`:7b`æˆ–`:72b`ï¼š
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">ollama run qwen2:7b
		  - #è¦é€€å‡ºï¼Œè¯·è¾“å…¥â€œ/byeâ€å¹¶æŒ‰ ENTER</span></span>
		  - ```
		  - æ‚¨è¿˜å¯ä»¥é€šè¿‡å…¶ä¸ OpenAI å…¼å®¹çš„ API è®¿é—® ollama æœåŠ¡ã€‚è¯·æ³¨æ„ï¼Œæ‚¨éœ€è¦ (1)`ollama serve`åœ¨ä½¿ç”¨è¯¥ API æ—¶ä¿æŒè¿è¡Œï¼Œä»¥åŠ (2)`ollama run qwen2:7b`åœ¨ä½¿ç”¨æ­¤ API ä¹‹å‰æ‰§è¡Œä»¥ç¡®ä¿æ¨¡å‹æ£€æŸ¥ç‚¹å·²å‡†å¤‡å°±ç»ªã€‚
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424"><span style="color:#aa0d91">ä»</span>openai<span style="color:#aa0d91">å¯¼å…¥</span>OpenAI
		  - å®¢æˆ·ç«¯ = OpenAI(
		  - base_url= <span style="color:#c41a16">'http://localhost:11434/v1/'</span> ,
		  - api_key= <span style="color:#c41a16">'ollama'</span> ,   <span style="color:#007400"># éœ€è¦ä½†è¢«å¿½ç•¥</span>
		  - chat_completion = client.chat.completions.create(
		  - messages=[
		  - {
		  	- <span style="color:#c41a16">'role'</span> : <span style="color:#c41a16">'user'</span> ,
		  	- <span style="color:#c41a16">'content'</span> : <span style="color:#c41a16">'è¯´è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•'</span> ,
		  - }
		  - ],
		  - model= <span style="color:#c41a16">'qwen2:7b'</span> ,
		  - )</span></span>
		  - ```
		  - ### ä½¿ç”¨ Alpaca æ•°æ®é›†å¯¹ Qwen 2 è¿›è¡Œå¾®è°ƒ
		  - ä»¥ä¸‹ä»£ç ä½¿ç”¨ Alpaca æ•°æ®é›†å¯¹ Qwen2â€“0.5B è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¯­è¨€æ¨¡å‹å¯¹äºæ–‡æœ¬ç”Ÿæˆã€æ‘˜è¦å’Œé—®ç­”ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡éå¸¸æœ‰æ•ˆã€‚
		  - **å…ˆå†³æ¡ä»¶ï¼š**æ‰€éœ€çš„è½¯ä»¶åŒ…å’Œåº“åŒ…æ‹¬ Unslothã€Xformers (Flash Attention)ã€trlã€peftã€accelerateã€bitsandbytesã€transformers å’Œ datasetsã€‚æ­¤ä»£ç æ—¨åœ¨åœ¨ Google Colab æˆ–å…¼å®¹ç¯å¢ƒä¸­è¿è¡Œã€‚
		  - **æ­¥éª¤ 1ï¼š**å®‰è£…ä¾èµ–é¡¹
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">!pip install <span style="color:#c41a16">"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"</span>
		  - !pip install --no <span style="color:#aa0d91">-deps</span> xformers <span style="color:#c41a16">"trl<0.9.0"</span> peft åŠ é€Ÿ bitsandbytes</span></span>
		  - ```
		  - **æ­¥éª¤ 2**ï¼šåŠ è½½æ¨¡å‹å’Œæ ‡è®°å™¨
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">ä» unsloth<span style="color:#aa0d91">å¯¼å…¥</span>FastLanguageModel
		  - <span style="color:#aa0d91">å¯¼å…¥</span> <span style="color:#5c2699">torch </span>
		  - <span style="color:#3f6e74">max_seq_length </span> =  <span style="color:#1c00cf">2048</span>
		  - dtype = <span style="color:#5c2699">None </span>
		  - <span style="color:#3f6e74">load_in_4bit </span> =  <span style="color:#5c2699">True </span>
		  - <span style="color:#3f6e74">fourbit_models </span> = [
		  - <span style="color:#c41a16">"unsloth/Qwen2-0.5b-bnb-4bit"</span> ,
		  - model, tokenizer = FastLanguageModel.from_pretrained(
		  - model_name = <span style="color:#c41a16">"unsloth/Qwen2-0.5B"</span> ,
		  - max_seq_length = max_seq_length,
		  - dtype = dtype,
		  - load_in_4bit = load_in_4bit,
		  - )</span></span>
		  - ```
		  - FastLanguageModel.from\_pretrained() å‡½æ•°åŠ è½½ Qwen2â€“0.5B æ¨¡å‹åŠå…¶ tokenizerã€‚å‚æ•° max\_seq\_lengthã€dtype å’Œ load\_in\_4bit ç”¨äºé…ç½®æ¨¡å‹ã€‚
		  - **æ­¥éª¤ 3ï¼š**åº”ç”¨ PEFTï¼ˆå‚æ•°æœ‰æ•ˆå¾®è°ƒï¼‰
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">æ¨¡å‹ = FastLanguageModel.get_peft_model(
		  - æ¨¡å‹,
		  - r = <span style="color:#1c00cf">16</span> ,
		  - target_modules = [ <span style="color:#c41a16">â€œq_projâ€</span> â€œ <span style="color:#c41a16">k_projâ€ </span><span style="color:#c41a16">â€œv_proj </span><span style="color:#c41a16">â€ â€œo_projâ€</span> â€œ
		  - <span style="color:#c41a16">gate_projâ€</span> â€œ <span style="color:#c41a16">up_projâ€</span> â€œ <span style="color:#c41a16">down_projâ€</span> ,], lora_alpha
		  - = <span style="color:#1c00cf">16</span> ,
		  - lora_dropout = <span style="color:#1c00cf">0</span> ,
		  - åè§ = <span style="color:#c41a16">â€œæ— â€</span> ,
		  - use_gradient_checkpointing = â€œ <span style="color:#c41a16">unslothâ€</span> ,
		  - random_state = <span style="color:#1c00cf">3407</span> ,
		  - use_rslora = <span style="color:#aa0d91">False</span> ,
		  - loftq_config = <span style="color:#aa0d91">None</span> ,
		  - )</span></span>
		  - ```
		  - FastLanguageModel.get\_peft\_model() å‡½æ•°ç”¨äºå°† PEFT åº”ç”¨äºåŠ è½½çš„æ¨¡å‹ã€‚å„ç§å‚æ•°ï¼ˆä¾‹å¦‚ rã€target\_modulesã€lora\_alphaã€lora\_dropoutã€biasã€use\_gradient\_checkpointingã€random\_stateã€use\_rslora å’Œ loftq\_configï¼‰ç”¨äºé…ç½® PEFT è¿‡ç¨‹ã€‚
		  - **æ­¥éª¤ 4ï¼š**å®šä¹‰ç¾Šé©¼æç¤º
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424">alpaca_prompt = <span style="color:#c41a16">"""ä¸‹é¢æ˜¯æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œä¸æä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥é…å¯¹ã€‚ç¼–å†™é€‚å½“å®Œæˆè¯·æ±‚çš„å“åº”ã€‚
		  - ### æŒ‡ä»¤ï¼š
		  - {}
		  - ### è¾“å…¥ï¼š
		  - {}
		  - ### å“åº”ï¼š
		  - {}"""</span>
		  - EOS_TOKEN = tokenizer.eos_token <span style="color:#007400"># å¿…é¡»æ·»åŠ  EOS_TOKEN </span>
		  - <span style="color:#aa0d91">def </span> formatting_prompts_func ( <span style="color:#5c2699">examples</span> ):
		  - instructions = examples[ <span style="color:#c41a16">"instruction"</span> ]
		  - input = examples[ <span style="color:#c41a16">"input"</span> ]
		  - output = examples[ <span style="color:#c41a16">"output"</span> ]
		  - texts = []
		  - <span style="color:#aa0d91">for</span> instructions, <span style="color:#5c2699">input</span> , output <span style="color:#aa0d91">in </span> <span style="color:#5c2699">zip</span> (instructions, input, output):
		  - text = alpaca_prompt.format (instruction, <span style="color:#5c2699">input</span> , output) + EOS_TOKEN         texts.append(text) <span style="color:#aa0d91">return</span> { <span style="color:#c41a16">"text"</span> : texts, <span style="color:#5c2699">}</span>
		  - </span></span>
		  - ```
		  - alpaca\_prompt å˜é‡æ˜¯æ ¼å¼åŒ–è¾“å…¥æ•°æ®çš„æ¨¡æ¿ã€‚EOS\_TOKEN å’Œ formatting\_prompts\_func() å‡½æ•°ç”¨äºå‡†å¤‡è®­ç»ƒæ•°æ®ã€‚
		  - **æ­¥éª¤5ï¼š**åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®é›†
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424"><span style="color:#aa0d91">ä»</span>æ•°æ®é›†<span style="color:#aa0d91">å¯¼å…¥</span>load_dataset
		  - æ•°æ®é›† = load_dataset( <span style="color:#c41a16">"yahma/alpaca-cleaned"</span> , split = <span style="color:#c41a16">"train"</span> )
		  - æ•°æ®é›† = æ•°æ®é›†.map <span style="color:#5c2699">(</span> formatting_prompts_func, batched = <span style="color:#aa0d91">True</span> ,)</span></span>
		  - ```
		  - ä½¿ç”¨ Hugging Face æ•°æ®é›†åº“ä¸­çš„ load\_dataset() å‡½æ•°åŠ è½½ Alpaca æ•°æ®é›†ã€‚ä½¿ç”¨ map() å‡½æ•°å°† formatting\_prompts\_func() å‡½æ•°åº”ç”¨äºæ•°æ®é›†ã€‚
		  - **æ­¥éª¤ 6ï¼š**è®¾ç½®è®­ç»ƒé…ç½®
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424"><span style="color:#aa0d91">ä»</span>trl<span style="color:#aa0d91">å¯¼å…¥</span>SFTTrainer
		  - <span style="color:#aa0d91">ä»</span>transformers<span style="color:#aa0d91">å¯¼å…¥</span>TrainingArguments
		  - <span style="color:#aa0d91">ä»</span>unsloth<span style="color:#aa0d91">å¯¼å…¥</span>is_bfloat16_supported
		  - trainer = SFTTrainer(
		  - model = model,
		  - tokenizer = tokenizer,
		  - train_dataset = dataset,
		  - dataset_text_field = <span style="color:#c41a16">"text"</span> ,
		  - max_seq_length = max_seq_length,
		  - dataset_num_proc = <span style="color:#1c00cf">2</span> ,
		  - args = TrainingArguments(
		  - per_device_train_batch_size = <span style="color:#1c00cf">2</span> ,
		  - gradient_accumulation_steps = <span style="color:#1c00cf">8</span> ,
		  - <span style="color:#007400"># ä½¿ç”¨ num_train_epochs = 1, warmup_ratio è¿›è¡Œå®Œæ•´è®­ç»ƒè¿è¡Œï¼</span>
		  	- warmup_steps = <span style="color:#1c00cf">20</span> ,
		  - max_steps = <span style="color:#1c00cf">120</span> ,
		  - learning_rate = <span style="color:#1c00cf">5e-5</span> ,
		  - fp16 = <span style="color:#aa0d91">not</span> is_bfloat16_supported(),
		  - bf16 = is_bfloat16_supported(),
		  - logstash_steps = <span style="color:#1c00cf">1</span> ,
		  - optim = <span style="color:#c41a16">"adamw_8bit"</span> ,
		  - weight_decay = <span style="color:#1c00cf">0.01</span>ï¼Œ
		  - lr_scheduler_type = <span style="color:#c41a16">â€œçº¿æ€§â€</span>ï¼Œ
		  - ç§å­= <span style="color:#1c00cf">3407</span>ï¼Œ
		  - output_dir = <span style="color:#c41a16">â€œè¾“å‡ºâ€</span>ï¼Œ
		  - ï¼‰ï¼Œ
		  - ï¼‰</span></span>
		  - ```
		  - trl åº“ä¸­çš„ SFTTrainer ç±»ç”¨äºè®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚TrainingArguments ç”¨äºé…ç½®å„ç§å‚æ•°ï¼Œä¾‹å¦‚æ‰¹å¤„ç†å¤§å°ã€æ¢¯åº¦ç´¯ç§¯æ­¥éª¤ã€é¢„çƒ­æ­¥éª¤ã€æœ€å¤§æ­¥éª¤ã€å­¦ä¹ ç‡ã€æ··åˆç²¾åº¦è®¾ç½®ã€è®°å½•æ­¥éª¤ã€ä¼˜åŒ–å™¨ã€æƒé‡è¡°å‡ã€å­¦ä¹ ç‡è°ƒåº¦ç¨‹åºå’Œç§å­ã€‚
		  - **æ­¥éª¤ 7ï¼š**è®­ç»ƒæ¨¡å‹
		  - ```ba
		  - <span style="background-color:#f9f9f9"><span style="color:#242424"><span style="color:#836c28">è®­ç»ƒå¸ˆç»Ÿè®¡</span>= è®­ç»ƒå¸ˆ.train()</span></span>
		  - ```
		  - è°ƒç”¨ trainer.train() å‡½æ•°å¯åŠ¨è®­ç»ƒè¿‡ç¨‹ã€‚trainer\_stats å˜é‡å­˜å‚¨è®­ç»ƒç»Ÿè®¡æ•°æ®ã€‚
		  - ç»è¿‡å¾®è°ƒçš„æ¨¡å‹å¯ç”¨äºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆã€æ‘˜è¦å’Œé—®ç­”ã€‚
		  -
		  - ### é«˜äº®
		  collapsed:: true
		  - > Hugging Face çš„ Open LLM Leaderboard [â¤´ï¸](https://omnivore.app/me/qwen-2-qwen-2-qwen-2-csdn-1917d392cab#dff3c760-6d49-4b22-a724-ecc3fa516f1f)
		  - [Omnivore å…¥é—¨ --- Getting Started with Omnivore](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2)
		  collapsed:: true
		  site:: [Omnivore](https://omnivore.app/zhangxinxin0216/getting-started-with-omnivore)
		  author:: unknown
		  labels:: [[æ’ä»¶ç±»]]
		  date-saved:: [[Aug 23rd, 2024]]
		  - ### é«˜äº®
		  collapsed:: true
		  - > * Saving å‚¨è“„
		   * Reading è¯»æ•°
		   * Organizing ç»„ç»‡
		   * Integrations é›†æˆ [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#ce4b3b05-d311-4b9e-bdcc-462d6d7496e6)
		  - > **å›¾ä¹¦é¦†**æ˜¯æ‚¨ Omnivore ä½“éªŒçš„ä¸­å¿ƒ [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#843cb26a-b673-4a42-afe2-7341c64a2343)
		  - > ä» Mac å­˜å‚¨ PDF [â¤´ï¸](https://omnivore.app/me/omnivore-getting-started-with-omnivore-1917cecd3e2#81e8fe5b-a27c-4e36-a2cb-7900a36c1731)
		  - [The Secret Power of â€˜Read It Laterâ€™ Appsï¼ˆã€Šå“ˆä½›å•†ä¸šè¯„è®ºã€‹æœ€è¿‘å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« ä¸ºè¿™ç§æ–°çš„ç¥ç»ç°è±¡å‘½åï¼šæ³¨æ„åŠ›ç¼ºé™·ç‰¹è´¨ï¼‰](https://omnivore.app/me/the-secret-power-of-read-it-later-apps)
		  site:: [Forte Labs](https://fortelabs.co/blog/the-secret-power-of-read-it-later-apps)
		  author:: Tiago Forte
		  labels:: [[æ’ä»¶ç±»]]
		  date-saved:: [[Aug 21st, 2024]]
		  date-published:: [[Jan 24th, 2022]]
		  -
		  - https://omnivore.app/me/rag-csdn-1917dcec1e0
		  -
		  - https://omnivore.app/me/qwen-2-qwen-2-qwen-2-csdn-1917d392cab
		  - [æ¢ç´¢çŸ¥è¯†ç®¡ç†æ–°ç»´åº¦ï¼šLogseq Anki Sync-CSDNåšå®¢](https://blog.csdn.net/gitblog_00070/article/details/139165044?ops_request_misc=&request_id=&biz_id=102&utm_term=logseq%E6%8F%92%E4%BB%B6&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-139165044.142^v100^pc_search_result_base3&spm=1018.2226.3001.4187)
		  collapsed:: true
		  - [logseq-anki-syncAn logseq to anki syncing plugin with superpowers - image occlusion, card direction, incremental cards, and a lot more.é¡¹ç›®åœ°å€:https://gitcode.com/gh\_mirrors/lo/logseq-anki-sync](https://gitcode.com/gh%5Fmirrors/lo/logseq-anki-sync/?utm%5Fsource=artical%5Fgitcode&index=top&type=card&webUrl)
		  - åœ¨ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œé«˜æ•ˆçš„çŸ¥è¯†ç®¡ç†å’Œè®°å¿†å·¥å…·æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚Logseq Anki Sync æ˜¯ä¸€æ¬¾å¼ºå¤§çš„æ’ä»¶ï¼Œå®ƒå°†æµè¡Œçš„æ€ç»´å¯¼å›¾è½¯ä»¶ Logseq ä¸è‘—åçš„é—´éš”é‡å¤å­¦ä¹ åº”ç”¨ Anki ç›´æ¥è¿æ¥èµ·æ¥ï¼Œè®©æ‚¨å¯ä»¥åœ¨ä¸¤ä¸ªå¹³å°ä¸Šæ— ç¼åŒæ­¥å’Œå¼ºåŒ–å­¦ä¹ ææ–™ã€‚
		  - ### é¡¹ç›®ç®€ä»‹
		  - Logseq Anki Sync æ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ’ä»¶ï¼Œå…è®¸æ‚¨å°† Logseq ä¸­çš„ç¬”è®°å†…å®¹ä»¥ä¸°å¯Œå¤šæ ·çš„å½¢å¼ï¼ˆåŒ…æ‹¬ Markdown å’Œ Org æ¨¡å¼ï¼‰å¯¼å…¥åˆ° Anki ä¸­è¿›è¡Œå¤ä¹ ã€‚è¿™ä¸ªæ’ä»¶ä¸ä»…æ”¯æŒå¸¸è§„çš„æ–‡æœ¬åŒæ­¥ï¼Œè¿˜æ¶µç›–äº† Logseq çš„è®¸å¤šé«˜çº§ç‰¹æ€§ï¼Œå¦‚ PDF æ³¨é‡Šã€æ•°å­¦å…¬å¼ç­‰ã€‚é€šè¿‡åˆ©ç”¨ Anki çš„æ™ºèƒ½ç®—æ³•å’Œä¸ªæ€§åŒ–è®¾ç½®ï¼Œæ‚¨å¯ä»¥æ‰“é€ ä¸€ä¸ªä¸ªæ€§åŒ–çš„å­¦ä¹ ç³»ç»Ÿã€‚
		  - ### æŠ€æœ¯åˆ†æ
		  - è¯¥æ’ä»¶è¿ç”¨äº†å…ˆè¿›çš„å“ˆå¸ŒæŠ€æœ¯æ¥æ£€æµ‹ Logseq æˆ– Anki ä¸­çš„å˜åŒ–ï¼Œç¡®ä¿åªåŒæ­¥æ›´æ–°çš„å†…å®¹ï¼ŒèŠ‚çœæ—¶é—´ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒå¤šç§å¡ç‰‡ç±»å‹ï¼Œå¦‚å›¾åƒé®æŒ¡ã€PDF é®æŒ¡ã€åŒå‘å¡ç‰‡ç­‰ï¼Œå¹¶ä¸”å®Œç¾åœ°åœ¨ Anki ä¸­å‘ˆç° Logseq çš„Markdownå’ŒOrgæ¨¡å¼å†…å®¹ã€‚å®‰è£…è¿‡ç¨‹ç®€å•æ˜äº†ï¼Œåªéœ€å‡ æ­¥å³å¯å®Œæˆã€‚
		  - ### åº”ç”¨åœºæ™¯
		  - Logseq Anki Sync å°¤å…¶é€‚ç”¨äºï¼š
		  - * çŸ¥è¯†å·¥ä½œè€…ï¼šéœ€è¦å¯¹å¤§é‡ä¿¡æ¯è¿›è¡Œæ•´ç†å’Œè®°å¿†çš„äººå£«ã€‚
		  - * å­¦ç”Ÿï¼šåœ¨å¤‡è€ƒæ—¶ï¼Œå¯ä»¥åˆ›å»ºç‰¹å®šçš„å¤ä¹ é›†åˆï¼ŒæŒ‰éœ€å­¦ä¹ ã€‚
		  - * æ•™å¸ˆï¼šä¸ºè¯¾ç¨‹åˆ›å»ºåŠ¨æ€çš„å­¦ä¹ èµ„æºåº“ã€‚
		  - ### é¡¹ç›®ç‰¹ç‚¹
		  - 1. **å…¨é¢çš„æ¸²æŸ“æ”¯æŒ**ï¼šä¸ä»…åŒæ­¥æ–‡æœ¬ï¼Œè¿˜åŒæ­¥å—å¼•ç”¨ã€é¡µé¢å¼•ç”¨ã€PDFæ³¨è§£ã€æ•°å­¦å…¬å¼ç­‰å„ç§å¤æ‚å†…å®¹ã€‚
		  - 2. **ä¸°å¯Œçš„é™„åŠ åŠŸèƒ½**ï¼šæ”¯æŒå›¾åƒé®æŒ¡ã€PDFå¤„ç†ã€æ–¹å‘å¡ã€å¢é‡å¡ç‰‡ç­‰ï¼Œæå‡å­¦ä¹ ä½“éªŒã€‚
		  - 3. **å……åˆ†åˆ©ç”¨AnkiåŠŸèƒ½**ï¼šä¸Ankiçš„é«˜çº§ç‰¹æ€§å…¼å®¹ï¼Œå¦‚è¿‡æ»¤ç‰Œç»„ã€çƒ­åŠ›å›¾ã€è¯­éŸ³åˆæˆç­‰ã€‚
		  - 4. **é«˜é€ŸåŒæ­¥**ï¼šé‡‡ç”¨æœ€æ–°å“ˆå¸ŒæŠ€æœ¯ï¼Œä»…åŒæ­¥å˜æ›´ï¼Œæé«˜æ•ˆç‡ã€‚
		  - ### ç»“è¯­
		  - å€ŸåŠ© Logseq Anki Syncï¼Œæ‚¨å¯ä»¥æ„å»ºä¸€ä¸ªæ—¢å¼ºå¤§åˆçµæ´»çš„çŸ¥è¯†ç®¡ç†ç³»ç»Ÿï¼Œå°†åˆ†æ•£çš„æ€è€ƒç¬”è®°è½¬åŒ–ä¸ºå¯Œæœ‰æˆæ•ˆçš„è®°å¿†ç»ƒä¹ ã€‚ç«‹å³å°è¯•å¹¶å‘æ˜å®ƒçš„æ½œåŠ›ï¼Œè®©æ‚¨çš„çŸ¥è¯†ç®¡ç†æ›´ä¸Šä¸€å±‚æ¥¼ï¼å¦‚æœä½ å–œæ¬¢è¿™ä¸ªå·¥å…·ï¼Œè¯·è€ƒè™‘èµåŠ©æ”¯æŒå¼€å‘è€…ï¼Œè®©ä»–ä»¬èƒ½å¤Ÿç»§ç»­ä¼˜åŒ–å’Œæ‰©å±•è¿™ä¸ªé¡¹ç›®ã€‚
		  - [logseq-anki-syncAn logseq to anki syncing plugin with superpowers - image occlusion, card direction, incremental cards, and a lot more.é¡¹ç›®åœ°å€:https://gitcode.com/gh\_mirrors/lo/logseq-anki-sync](https://gitcode.com/gh%5Fmirrors/lo/logseq-anki-sync/?utm%5Fsource=artical%5Fgitcode&index=bottom&type=card&webUrl)
		  - [æ¨èä¸€æ¬¾ç¥å¥‡çš„Logseqæ’ä»¶ï¼šLuckysheetå¢å¼ºç‰ˆæ—¥å¿—ç®¡ç†ä½“éªŒ-CSDNåšå®¢](https://blog.csdn.net/gitblog_00065/article/details/137366090?ops_request_misc=&request_id=&biz_id=102&utm_term=logseq%E6%8F%92%E4%BB%B6&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-137366090.142^v100^pc_search_result_base3&spm=1018.2226.3001.4187)
		  - [ä¸‰æ¬¾é¡¶çº§å¼€æºRAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)å·¥å…·ï¼šVerbaã€Unstructured å’Œ Neum-CSDNåšå®¢](https://blog.csdn.net/XianxinMao/article/details/136575056?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-136575056-blog-141191700.235%5Ev43%5Epc_blog_bottom_relevance_base9&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-136575056-blog-141191700.235%5Ev43%5Epc_blog_bottom_relevance_base9&utm_relevant_index=1)
		  collapsed:: true
		  - **æ¦‚è¿°**
		  - éšç€ä¼ä¸šå¯¹è¯å¼æ•°æ®å¤„ç†éœ€æ±‚çš„æå‡ï¼Œé¢ä¸´çš„æŒ‘æˆ˜æ˜¯æ•°æ®éšç§æ€§å’Œç¼ºä¹ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆã€‚è™½ç„¶ç±»ä¼¼LangChainèƒ½åœ¨çŸ­æ—¶é—´å†…æ„å»ºRAGåº”ç”¨ï¼Œä½†å¿½è§†äº†æ–‡æ¡£è§£æã€å¤šæ¥æºæ•°æ®ETLã€æ‰¹é‡å¤„ç†ã€è®¿é—®æ§åˆ¶ç­‰é—®é¢˜ã€‚æ­¤æ–‡è¯„ä¼°äº†ä¸‰æ¬¾å¼€æºRAGå·¥å…·çš„æ½œåŠ›ï¼Œä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡ã€‚
		  - #### Verbaï¼šç†æƒ³çš„RAGé€‰æ‹©
		  - * Weaviateæä¾›çš„Verbaé¡¹ç›®å¼ºè°ƒæ˜“ç”¨æ€§ï¼Œæ˜¯RAGåº”ç”¨è€Œéæ¡†æ¶ã€‚
		  - * æä¾›ä¸å¤šç§åµŒå…¥æ¨¡å—çš„é›†æˆï¼Œå¦‚GPT3/4å’ŒCohereã€‚
		  - * æ”¯æŒPDFå’Œçº¯æ–‡æœ¬ç­‰å¤šç§æ–‡ä»¶æ ¼å¼çš„è§£æã€‚
		  - * æä¾›å¿«é€Ÿå…¥é—¨å’ŒDockeréƒ¨ç½²é€‰é¡¹ã€‚
		  - #### Unstructuredï¼šä¸“æ³¨æ•°æ®ETLçš„RAGæ¡†æ¶
		  - * ä¸“æ³¨äºç»Ÿä¸€å’Œè½¬æ¢ä¸åŒæ•°æ®æ ¼å¼ä»¥é€‚é…å‘é‡æ•°æ®åº“å’ŒLLMæ¡†æ¶ã€‚
		  - * æä¾›å¤šç§æ–‡ä»¶ç±»å‹æ”¯æŒå’Œ20å¤šç§æ•°æ®æºã€‚
		  - * åŸºäºæ–‡æ¡£æ¨¡å‹çš„å…ƒç´ è½¬æ¢å’Œä¼˜åŒ–ã€‚
		  - **å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼š**
		  - * ä½¿ç”¨pipå®‰è£…å®¢æˆ·ç«¯ã€‚
		  - * æ³¨å†ŒAPIå¯†é’¥æˆ–ä½¿ç”¨Dockerè‡ªä¸»æ‰˜ç®¡APIã€‚
		  - #### Neumï¼šç®¡é“å¼çš„RAGæ¡†æ¶
		  - * Meruemæ–°æ¨å‡ºçš„RAGå¹³å°å¼ºè°ƒæºã€è¿æ¥å™¨å’Œç»ˆç‚¹ç­‰æ¸…æ™°å®šä¹‰ã€‚
		  - * å…³æ³¨å¤§è§„æ¨¡æ•°æ®æ‘„å–é—®é¢˜ï¼Œæ”¯æŒè¯­ä¹‰åˆ†å—ï¼ˆLLMå®šä¹‰çš„åˆ†å—ç­–ç•¥ï¼‰ã€‚
		  - * æä¾›æ— ä»£ç ç®¡çº¿æ„å»ºå™¨ï¼Œå¹¶æœ‰æ¸…æ™°è¯­æ³•çš„Pipelineé…ç½®ã€‚
		  - **å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼š**
		  - * å®‰è£…neumaiåï¼ŒæŒ‰ç…§æŒ‡å—åˆ›å»ºç¬¬ä¸€ä¸ªPipelineã€‚
		  - * é¢„æœŸæœªæ¥ä¼šå¢åŠ Dockeræ”¯æŒå’Œæ›´å®Œå–„çš„æ–‡æ¡£ã€‚
		  - #### å±•æœ›
		  - * Verbaã€Unstructuredå’ŒNeumå¯ç»“åˆä½¿ç”¨ï¼Œæ„å»ºæ¥è¿‘å®Œæ•´çš„ç”Ÿäº§å°±ç»ªå‹RAGåº”ç”¨ã€‚
		  - * ç›¸å…³å·¥å…·çš„äº¤å‰æ•´åˆå°†é©±åŠ¨å¼€æºRAGå·¥å…·çš„æŒç»­å‘å±•ã€‚
		  - #### å°ç»“
		  - å¼€æºç¤¾åŒºæ­£åœ¨ç§¯ææ¨è¿›RAGå·¥å…·çš„å‘å±•ï¼Œæä¾›ä¼ä¸šçº§çš„æ•°æ®å¤„ç†è§£å†³æ–¹æ¡ˆã€‚ä¸è®ºæ˜¯Verbaæä¾›çš„ç”¨æˆ·ç•Œé¢ï¼Œè¿˜æ˜¯Unstructuredå’ŒNeumçš„æ–‡æ¡£å¤„ç†ä¸ç®¡çº¿ä»£ç ï¼Œéƒ½é¢„ç¤ºäº†RAGæŠ€æœ¯çš„å…‰æ˜æœªæ¥ã€‚
		  - [å§œèçš„å¥¥æ•°èµ›æˆç»©å³å°†å…¬å¸ƒï¼Œç½‘å‹ç­‰ä¸åŠäº†ï¼š8æœˆä»½äº†ï¼Ÿ (baidu.com)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8960619479621035962%22%7D&n_type=-1&p_from=-1)
		  collapsed:: true
		  - #æ·±åº¦å¥½æ–‡è®¡åˆ’#æ—¶é—´è¿‡å¾—çœŸå¿«ã€‚ä¸€è½¬çœ¼ï¼Œä»6æœˆåˆæ¥åˆ°äº†8æœˆã€‚å§œèçš„æ•°èµ›æ’åï¼Œæƒ³å¿…ä¹Ÿè¦å‡ºæ¥äº†å§ã€‚
		  - 6ä»½ï¼Œé˜¿é‡Œå·´å·´å…¨çƒæ•°èµ›åï¼Œä¸€åæ¥è‡ªæ±Ÿè‹æ¶Ÿæ°´çš„ä¸­ä¸“ç”Ÿï¼Œå§œèè·å¾—äº†å…¨çƒæ’åç¬¬12åã€‚ä¸€æ—¶é—´ï¼Œå› ä¸ºè¿™ä½è‡ªå¸¦è¯é¢˜çš„å¥³å­©ï¼Œä»æ­¤å‡ºåœˆäº†ã€‚
		  - æ’åœ¨å¥¹å‰é¢çš„ï¼Œéƒ½æ˜¯æ¥è‡ªå…¨çƒå„å¤§åæ ¡ï¼Œéƒ½æ˜¯å¤§æœ‰æ¥å¤´ï¼Œéƒ½æ˜¯æœ‰å¾ˆå¼ºç¡¬çš„æ•°å­¦èƒŒæ™¯çš„äººæ‰ã€‚å”¯ç‹¬å¥¹ï¼Œå§œèï¼Œä¸€åæ¥è‡ªä¸­ä¸“çš„17å²å¥³å­©ã€‚
		  - å¥¹ä¸ä»…ä¸æ˜¯å¤§å­¦ç”Ÿï¼Œä¹Ÿä¸æ˜¯æ¥è‡ªç‰¹åˆ«å¯Œè£•çš„å®¶åº­ï¼Œä½†æ­£å› ä¸ºè¿™å·¨å¤§çš„å·®åˆ«ï¼Œå¥¹å‚åŠ çš„é˜¿é‡Œå·´å·´çš„æ•°èµ›æ’å12ï¼Œè®©å¥¹æœ‰äº†ä¸ä¸€æ ·çš„å…‰èŠ’ã€‚
		  - ![](https://pics1.baidu.com/feed/c83d70cf3bc79f3d9a2f72478d5a481f708b2980.jpeg@f_auto?token=0fa10631829d5a3f66f74830386e74f9)
		  - å¯¹äºè¿™æ ·çš„ä¸€ä½å¤©æ‰å°‘å¥³ï¼Œäººæ°‘æ—¥æŠ¥ä¹Ÿæ˜¯äº²è‡ªå‘æ–‡æŠ¥é“ã€‚æƒ³ä¸€æƒ³ï¼Œåœ¨å¹³å‡¡çš„äººä¸­é—´ï¼Œéš¾æœ‰å‡ ä¸ªäººå¯ä»¥å‡­å€Ÿç€å¹³å‡¡çš„èº«ä¸–ï¼Œå‡­å€Ÿç€ä¸€æ¬¡ç«èµ›ï¼Œå¯ä»¥çªç ´åœˆå±‚ï¼Œå¯ä»¥è¾¾åˆ°ä»¤å…¨ä¸–ç•Œæ³¨ç›®çš„è£è€€ï¼Œå”¯æœ‰ç”¨å¤©æ‰ï¼Œæ‰èƒ½è§£é‡Šå¾—äº†ã€‚
		  - å› ä¸ºå§œèçš„å‡ºåœˆï¼Œå¥¹çš„çˆ¶æ¯è™½ç„¶å¹´é¾„å¾ˆå¤§ï¼Œå´å› ä¸ºè¦æŠšè‚²ä¸¤ä¸ªå­©å­ï¼Œä¾ç„¶åœ¨å¤–åœ°æ‰“å·¥ï¼Œè€Œå¥¹çš„æ¯äº²å› ä¸ºèº«ä½“ä¸å¥½ï¼Œæ²»ç–—åï¼Œæ›´æ˜¯æ¬ ä¸‹äº†ä¸€ç¬”å€ºã€‚
		  - è€Œå¥¹çš„å§å§ï¼Œæ˜¯ä¸€ååœ¨è¯»å¤§å­¦ç”Ÿâ€¦â€¦ç­‰ç­‰è¿™äº›ä¿¡æ¯ï¼Œå› ä¸ºç½‘å‹ä»¬çš„ç–¯ç‹‚è¿½æ…•ï¼Œä»è€Œä»ä¾§é¢äº†è§£äº†å§œèä¸€å®¶çš„æƒ…å†µã€‚æ­£æ˜¯å› ä¸ºè¿™ä¸ªæ¥è‡ªå¹³å‡¡ï¼Œæ¥è‡ªä¸­ä¸“çš„å¥³å­©ï¼Œå´è·å¾—äº†å¦‚æ­¤çš„æ’åï¼Œä¸€å¤œæˆåï¼Œä¹Ÿæ˜¯åœ¨å¸¸ç†ä¹‹ä¸­äº†ã€‚
		  - è€Œå¥¹çš„è€å¸ˆï¼Œç‹é—°ç§‹ï¼Œä½œä¸ºå§œèçš„ç­ä¸»ä»»å…¼æ•°å­¦è€å¸ˆï¼Œä¹Ÿè¢«åª’ä½“é‡‡è®¿ã€‚è¢«ç½‘å‹ä»¬æ¬£å–œåœ°ç§°ä¹‹ä¸ºâ€œåƒé‡Œé©¬å¸¸æœ‰ï¼Œè€Œä¼¯ä¹ä¸å¸¸æœ‰ã€‚â€é‡Œä¼¯ä¹çš„ä¼¯ä¹ã€‚
		  - ![](https://pics1.baidu.com/feed/f3d3572c11dfa9ecbb4e5f6e552b720d908fc174.jpeg@f_auto?token=247bcf550098fc60ef8d2f667071b83a)
		  - å¯¹äºå§œèèƒ½è·å¾—è¿™æ ·ä¸€ä»½è£èª‰ï¼Œå°¤å…¶æ˜¯å‡ºèº«ä¸å®¶ä¸–è¿™æ ·å·¨å¤§çš„è½å·®ï¼Œä¸å°‘åŒæ ·å¹³å‡¡çš„äººä¸ºå¥¹é«˜å…´ï¼Œä¸ºå¥¹åº†ç¥ï¼Œä½†æœ‰äº›èº«ä»½ä¸ä¸€æ ·çš„äººå´åœ¨è´¨ç–‘å¥¹ï¼Œç”šè‡³å…¬å¼€è¯½è°¤å¥¹ã€‚
		  - é‚£äº›è´¨ç–‘çš„äººï¼Œä»å¥¹çš„æ¿ä¹¦å¼€å§‹ï¼Œæˆªå›¾è¯¦ç»†åœ°é“æ¥ï¼Œä¼¼ä¹æœ‰ç†æœ‰æ®ã€‚ä¸€æ—¶é—´ï¼Œæœ‰å…³å§œèçš„å„ç§è´¨ç–‘å’Œè®®è®ºï¼Œå¦‚æ³¢æ¶›èˆ¬çº·è‡³æ³æ¥ã€‚è´¨ç–‘å¥¹ä¸€ä½æ¯«æ— æ•°å­¦ç»éªŒçš„å¥³å­©ï¼Œå¦‚ä½•èƒ½åœ¨è¿™å…¨çƒæ€§çš„ç«èµ›ä¸­ä»¥æ’å12èƒœå‡ºï¼Œå…¶ä¸­è‚¯å®šè—æœ‰ä¸å¯å‘Šäººçš„å¼„è™šä½œå‡ï¼Œæˆ–è€…èƒŒåæœ‰å›¢é˜Ÿåœ¨åŠ¨ä½œã€‚
		  - ç”šè‡³è¿˜æœ‰ä¸€ä½å«èµµæ–Œçš„åŒ—å¤§ç¡•å£«å®åè´¨ç–‘ï¼Œå¹¶æ„¿æ„ç”¨500ä¸‡å¯¹èµŒã€‚ç»“æœè™½ç„¶ä¸äº†äº†ä¹‹ï¼Œä½†å› ä¸ºå®åè·³å‡ºæ¥ï¼Œå€’ä¹Ÿå¸å¼•äº†ä¸€å¤§æ³¢çš„è¯é¢˜ å’Œäº‰è®®ã€‚
		  - è¿˜æœ‰åŒ—å¤§æ•°å­¦å®¶è¢æ–°æ„ç­‰äººï¼Œç”šè‡³è¿˜å‡ºç°äº†å¤šåå‚èµ›é€‰æ‰‹å‘è”åä¿¡ï¼Œè¦æ±‚è¾¾æ‘©é™¢å…¬å¼€å§œèåˆèµ›è¯•å·çš„äº‹æƒ…ã€‚
		  - ![](https://pics5.baidu.com/feed/f11f3a292df5e0fea6ad3c6d089bb1a65fdf722a.jpeg@f_auto?token=13f7b262433d9c4be63cb4f585d5105c)
		  - è¿™äº›è´¨ç–‘è¿˜ä¸æ˜¯ç®€å•çš„ä¸€å¥è¯ï¼Œä»–ä»¬ä»å¤šä¸ªç»´åº¦ç»™å‡ºäº†è‡ªå·±çš„ä¾æ®ï¼Œå°¤å…¶æ˜¯æ•°å­¦å®¶è¢æ–°æ„ï¼Œä»éå¸¸ç†æ€§çš„è§’åº¦è¡¨è¾¾äº†è‡ªå·±çš„è§‚ç‚¹ï¼Œå¸Œæœ›å§œèèƒ½è‡ªè¯æ¸…ç™½ã€‚
		  - åé¢åˆå‡ºç°äº†37åå­¦ç”Ÿè”åè¯·æ„¿ï¼Œè¦æ±‚å§œèå½“ä¼—è€ƒè¯•ã€‚è¿™æ ·çš„ä¸€ç•ªæ“ä½œï¼Œè®©å¸Œæœ›å§œèå¥½ï¼Œæ„¿æ„å§œèå¥½çš„å¹³å¤´è€ç™¾å§“æ— è¯­äº†ï¼Œä¹Ÿæ„¤æ€’äº†ã€‚ä¸€ä¸ªå¥³å­©èƒ½è¿™æ ·æœ‰å‡ºæ¯ï¼Œä»–ä»¬å±…ç„¶ä¸é«˜å…´ï¼Œåè€Œå¹æ¯›æ±‚ç–µè´¨ç–‘è¿™è´¨ç–‘é‚£ï¼Œä¹Ÿè®©äººæ‚²å“€ã€‚
		  - é¢å¯¹è¿™äº›äººçš„è´¨ç–‘ï¼Œå§œèåŠå®¶å±å¹¶æ²¡æœ‰å›åº”ã€‚å§œèä¾ç„¶åœ¨è§„å®šçš„æ—¥å­å‚åŠ äº†å†³èµ›ã€‚
		  - äºæ˜¯ï¼Œæ‰€æœ‰äººéƒ½æŠŠå¸Œæœ›å¯„æ‰˜åœ¨å†³èµ›çš„æ’åä¸Šï¼Œå¸Œæœ›å§œèå†æ¬¡ä»¥å®åŠ›æ¥æ‰“è¿™ä¸€ä¼—æ— èŠçš„æœ‰èº«ä»½æœ‰åœ°ä½äººçš„å˜´ã€‚
		  - ä¾æ®2024é˜¿é‡Œå…¨çƒæ•°èµ›ç»„ç»‡æ–¹è¾¾æ‘©é™¢æ¶ˆæ¯ï¼Œ8æœˆä»½å°†å…¬å¸ƒå†³èµ›æˆç»©ï¼Œç°åœ¨å·²ç»æ˜¯8æœˆä»½äº†ï¼Œå¾ˆå¤šç½‘å‹å·²ç»ç­‰ä¸åŠäº†ï¼Œçº·çº·åœ¨è¾¾æ‘©é™¢çš„è§†é¢‘ä¸‹æ–¹æ‰“å¡ç•™è¨€ï¼Œæé†’å°½å¿«å…¬å¸ƒå§œèçš„ç«èµ›æˆç»©ã€‚
		  - ![](https://pics4.baidu.com/feed/18d8bc3eb13533fa889d6a41fc28781140345bbb.jpeg@f_auto?token=11ca71e8ba559f568044cc2749810f7f)
		  - æœ‰è¶£çš„æ˜¯ï¼Œè¿›å…¥8æœˆåï¼Œå‡ ä¹æ¯å¤©éƒ½æœ‰å¤§é‡ç½‘å‹åœ¨å®£ä¼ å§œèçš„è§†é¢‘ä¸‹æ–¹ç•™è¨€ï¼Œçº·çº·æé†’æ—¶é—´åˆ°äº†ã€‚
		  - ä¸è¿‡ï¼Œè¾¾æ‘©é™¢å¹¶æœªå›å¤ä»»ä½•ç½‘å‹çš„ç•™è¨€ï¼Œè¿™è®©ç¿˜é¦–ä»¥å¾…çš„ç½‘å‹æ„Ÿåˆ°ç‰¹åˆ«çš„å¿ƒç„¦ã€‚
		  - æ›´è®©ç½‘å‹å¿ƒç„¦çš„æ˜¯ï¼Œè¾¾æ‘©é™¢è‡ª6æœˆä»½ä¹‹åï¼Œå°±å†æ²¡æœ‰ç»§ç»­æ›´æ–°ä»»ä½•è§†é¢‘ã€‚æ®è¯´ï¼Œæ­¤å‰å‡ ä¹æ˜¯ä¸æ–­æ›´çš„ã€‚ç½‘å‹ä»¬è¶Šæ˜¯æƒ³æ—©ä¸€ç‚¹çŸ¥é“ç«èµ›çš„ç»“æœï¼Œå¯¹æ–¹è¶Šæ˜¯ä¸€æ³¢æ— æ¼¾ã€‚
		  - ä½ è¯´ï¼Œè¿™æ˜¯ä¸æ˜¯ä¸€æ‹³æ‰“åœ¨äº†æ£‰èŠ±ä¸Šã€‚ä»»æ˜¯ä½ ç€æ€¥ï¼Œä¹Ÿæ˜¯æ²¡æœ‰ä»»ä½•ä½œç”¨çš„ã€‚
		  - ![](https://pics0.baidu.com/feed/21a4462309f790522cacbed4340852c479cbd5b7.jpeg@f_auto?token=9fede491df283ac24697fd6dafd9e37f)
		  - äºæ˜¯ï¼Œå¤§å®¶åªå¥½é™ä¸‹å¿ƒæ¥ç­‰å¾…ã€‚å¸Œæœ›åˆ°äº†æ—¶é—´ï¼Œè¾¾æ‘©é™†å†›å¯ä»¥å¦‚æœŸå…¬å¸ƒå†³èµ›åå•ã€‚
		  - å¤§å®¶å¦‚æ­¤æœŸå¾…å†³èµ›åå•çš„å®£å¸ƒï¼Œæˆ‘æƒ³ï¼Œå¹¶ä¸æ˜¯å»å…³æ³¨ç¬¬ä¸€åï¼Œç¬¬äºŒåï¼Œç”šè‡³å‰ååï¼Œè€Œæ˜¯åœ¨å…³æ³¨æ­¤å‰å‡ºç°äº‰è®®ï¼Œä½œä¸ºä¸€åå­¦ä¹ æœè£…è®¾è®¡çš„ä¸­ä¸“ç”Ÿçš„å§œèã€‚
		  - ![](https://pics2.baidu.com/feed/8694a4c27d1ed21b130fe18c9a9558ca53da3f9a.jpeg@f_auto?token=a4d98068b7c27aceff3e5976770c156b)
		  - åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå–œæ¬¢å§œèçš„ç²‰ä¸å¸Œæœ›æ•°å­¦å¤§èµ›ä¸»åŠæ–¹å°½å¿«å…¬å¸ƒå†³èµ›æˆç»©ï¼Œå¸®åŠ©å§œèæ¾„æ¸…äº‹å®ï¼Œè¦ç”¨å®åŠ›æ¥è¯æ˜è‡ªå·±çš„æ¸…ç™½ï¼›å½“ç„¶ä¹Ÿæœ‰éƒ¨åˆ†ç½‘å‹ï¼Œå¸Œæœ›ç”¨ç»“æœæ¥è¯å®è‡ªå·±çš„è´¨ç–‘ã€‚
		  - [å§œèå†³èµ›æˆç»©æœªå…¬å¸ƒï¼Œå®¶å±å¦è®¤æ‹¿ç¬¬8åï¼Œè¿™åœºé—¹å‰§è¯¥ç»“æŸäº† (msn.cn)](https://www.msn.cn/zh-cn/news/other/%E5%A7%9C%E8%90%8D%E5%86%B3%E8%B5%9B%E6%88%90%E7%BB%A9%E6%9C%AA%E5%85%AC%E5%B8%83-%E5%AE%B6%E5%B1%9E%E5%90%A6%E8%AE%A4%E6%8B%BF%E7%AC%AC8%E5%90%8D-%E8%BF%99%E5%9C%BA%E9%97%B9%E5%89%A7%E8%AF%A5%E7%BB%93%E6%9D%9F%E4%BA%86/ar-AA1ppXrG?ocid=msedgntp&pc=U531&cvid=66cbedba42cd426989a1aca51648733a&ei=13)
		  - [å¼€æºRAGæ¡†æ¶æ±‡æ€»-CSDNåšå®¢](https://blog.csdn.net/qq_33137873/article/details/138683590?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-138683590-blog-141191700.235%5Ev43%5Epc_blog_bottom_relevance_base9&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-138683590-blog-141191700.235%5Ev43%5Epc_blog_bottom_relevance_base9&utm_relevant_index=2)
		  collapsed:: true
		  - æœ¬æ–‡æœé›†äº†ä¸€äº›å¼€æºçš„åŸºäºLLMçš„RAGï¼ˆRetrieval-Augmented Generationï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å¸çº³ä¸šç•Œæœ€æ–°çš„RAGåº”ç”¨æ–¹æ³•ä¸æ€è·¯ã€‚å¦‚æœ‰é”™è¯¯æˆ–è€…æ„è§å¯ä»¥æå‡ºï¼ŒåŒæ—¶ä¹Ÿæ¬¢è¿å¤§å®¶æŠŠè‡ªå·±å¸¸ç”¨è€Œè¿™é‡Œæœªåˆ—å‡ºçš„æ¡†æ¶è´¡çŒ®å‡ºæ¥ï¼Œæ„Ÿè°¢\~
		  - ## RAGåº”ç”¨æ¡†æ¶
		  - * é¡¹ç›®åœ°å€ï¼šhttps://github.com/infiniflow/ragflow
		  - * ç®€ä»‹ï¼šRAGFlow æ˜¯ä¸€æ¬¾åŸºäºæ·±åº¦æ–‡æ¡£ç†è§£æ„å»ºçš„å¼€æº RAGï¼ˆRetrieval-Augmented Generationï¼‰å¼•æ“ã€‚RAGFlow å¯ä»¥ä¸ºå„ç§è§„æ¨¡çš„ä¼ä¸šåŠä¸ªäººæä¾›ä¸€å¥—ç²¾ç®€çš„ RAG å·¥ä½œæµç¨‹ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é’ˆå¯¹ç”¨æˆ·å„ç±»ä¸åŒçš„å¤æ‚æ ¼å¼æ•°æ®æä¾›å¯é çš„é—®ç­”ä»¥åŠæœ‰ç†æœ‰æ®çš„å¼•ç”¨ã€‚
		  - * ç‰¹æ€§ï¼šOCRã€**å†…ç½®å¤šç§æ–‡æ¡£åˆ‡åˆ†æ¨¡æ¿**ã€æ–‡æ¡£åˆ‡åˆ†å¯è§†åŒ–å¹¶ä¸”å¯ä¿®æ”¹ã€å…¼å®¹å¤šç§æ–‡æ¡£æ•°æ®ç±»å‹
		  - * æ¶æ„ï¼š
		  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/c34b905634e04be0adfd2450be41e4cb.png#pic_center)
		  - * ç¡¬ä»¶è¦æ±‚ï¼šCPU >= 4 æ ¸ã€RAM >= 16 GBã€Disk >= 50 GBã€Docker >= 24.0.0 & Docker Compose >= v2.26.1
		  - * é¡¹ç›®åœ°å€ï¼š https://github.com/netease-youdao/QAnything
		  - * ç®€ä»‹ï¼šQAnything ( Q uestion based on Anything ) æ˜¯è´¡çŒ®æ”¯æŒä»»ä½•æ ¼å¼æ–‡ä»¶æˆ–æ•°æ®åº“çš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿï¼Œå¯æ–­ç½‘å®‰è£…ä½¿ç”¨ã€‚æ‚¨çš„ä»»ä½•æ ¼å¼çš„æœ¬åœ°æ–‡ä»¶éƒ½å¯ä»¥å¾€é‡Œæ‰”ï¼Œå³å¯è·å¾—å‡†ç¡®ã€å¿«é€Ÿã€é è°±çš„é—®ç­”ä½“éªŒã€‚
		  - * ç‰¹æ€§ï¼šæ”¯æŒç¦»çº¿å®‰è£…ä½¿ç”¨ã€**è·¨è¯­ç§é—®ç­”**ã€**ç²—æ’å’Œç²¾æ’çš„äºŒé˜¶æ®µå¬å›**
		  - * æ¶æ„ï¼š
		  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/d34724e9c483434dbf88896885b839d8.png#pic_center)
		  - * ç¡¬ä»¶è¦æ±‚ï¼šæœ€ä½CPUå³å¯ï¼›ä½¿ç”¨GPUç¯å¢ƒéœ€è¦NVIDIA GPU Memory >= 4GB (use OpenAI API) & Docker Desktop >= 4.26.1ï¼ˆ131620ï¼‰
		  - * é¡¹ç›®åœ°å€ï¼šhttps://github.com/open-webui/open-webui
		  - * ç®€ä»‹ï¼šOpen WebUI æ˜¯ä¸€ä¸ªå¯æ‰©å±•ã€åŠŸèƒ½ä¸°å¯Œä¸”ç”¨æˆ·å‹å¥½çš„è‡ªæ‰˜ç®¡ WebUIï¼Œæ—¨åœ¨å®Œå…¨ç¦»çº¿æ“ä½œã€‚å®ƒæ”¯æŒå„ç§ LLM è¿è¡Œç¨‹åºï¼ŒåŒ…æ‹¬ Ollama å’Œ OpenAI å…¼å®¹çš„ APIã€‚
		  - * ç‰¹æ€§ï¼š**åŸç”Ÿæ”¯æŒOllama**ã€**æ”¯æŒå®‰è£…å’Œå¸è½½æ¨¡å‹**ã€**æ”¯æŒå¤šæ¨¡æ€æ¨¡å‹**ã€**æ”¯æŒåˆ‡æ¢æ¨¡å‹**ã€**å¤šç”¨æˆ·ç®¡ç†**
		  - * æ¶æ„ï¼š
		  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/413e61ac41fb4c1d981194df467de82f.gif#pic_center)
		  - * ç¡¬ä»¶è¦æ±‚ï¼šæœ€ä½CPUå³å¯ï¼Œä½¿ç”¨GPUç¯å¢ƒéœ€è¦NVIDIA GPU Memory >= 4GB (å–å†³äºä½¿ç”¨Ollamaçš„æ¨¡å‹å¤§å°)
		  - * é¡¹ç›®åœ°å€ï¼šhttps://github.com/labring/FastGPT
		  - * ç®€ä»‹ï¼šFastGPT æ˜¯ä¸€ä¸ªåŸºäº LLM å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿï¼Œæä¾›å¼€ç®±å³ç”¨çš„æ•°æ®å¤„ç†ã€æ¨¡å‹è°ƒç”¨ç­‰èƒ½åŠ›ã€‚åŒæ—¶å¯ä»¥é€šè¿‡ Flow å¯è§†åŒ–è¿›è¡Œå·¥ä½œæµç¼–æ’ï¼Œä»è€Œå®ç°å¤æ‚çš„é—®ç­”åœºæ™¯ï¼
		  - * ç‰¹æ€§ï¼š**æ”¯æŒåº”ç”¨ç¼–æ’**ã€**å…ç™»å½•åˆ†äº«**ã€**æ”¯æŒæ¥å…¥é£ä¹¦ã€ä¼ä¸šå¾®ä¿¡ç­‰åº”ç”¨**
		  - * æ¶æ„ï¼š
		  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/4a0319a9d1834a3aae3b219557bb9128.webp#pic_center)
		  - * ç¡¬ä»¶è¦æ±‚ï¼šCPU >= 2 æ ¸ã€RAM >= 4 GBç”¨äºå®‰è£…æ•°æ®åº“ï¼ŒGPUå–å†³äºä½¿ç”¨çš„æ¨¡å‹
		  - * é¡¹ç›®åœ°å€ï¼šhttps://github.com/chatchat-space/Langchain-Chatchat
		  - * ç®€ä»‹ï¼šåŸºäº ChatGLM ç­‰å¤§è¯­è¨€æ¨¡å‹ä¸ Langchain ç­‰åº”ç”¨æ¡†æ¶å®ç°ï¼Œå¼€æºã€å¯ç¦»çº¿éƒ¨ç½²çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å¤§æ¨¡å‹çŸ¥è¯†åº“é¡¹ç›®ã€‚
		  - * ç‰¹æ€§ï¼šç®—æ˜¯æ¯”è¾ƒæ—©æœŸçš„RAGæ¡†æ¶äº†ï¼Œä½¿ç”¨çš„åŸºæœ¬å…¨æ˜¯pythonçš„æ¡†æ¶ã€‚è¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªå¯ä»¥å®ç°**å®Œå…¨æœ¬åœ°åŒ–**æ¨ç†çš„çŸ¥è¯†åº“å¢å¼ºæ–¹æ¡ˆ, é‡ç‚¹è§£å†³æ•°æ®å®‰å…¨ä¿æŠ¤ï¼Œç§åŸŸåŒ–éƒ¨ç½²çš„ä¼ä¸šç—›ç‚¹ã€‚æ”¯æŒå¸‚é¢ä¸Šä¸»æµçš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹å’ŒEmbeddingæ¨¡å‹ï¼Œæ”¯æŒå¼€æºçš„æœ¬åœ°å‘é‡æ•°æ®åº“ã€‚ æœ¬å¼€æºæ–¹æ¡ˆé‡‡ç”¨Apache Licenseï¼Œå¯ä»¥**å…è´¹å•†ç”¨ï¼Œæ— éœ€ä»˜è´¹**ã€‚
		  - * æ¶æ„ï¼š
		  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/d891ea4ac20e4827bea7845a34de0990.png#pic_center)
		  - * ç¡¬ä»¶è¦æ±‚ï¼šå¯¹GPUè¦æ±‚è¾ƒé«˜
		  - * é¡¹ç›®åœ°å€ï¼šhttps://github.com/1Panel-dev/MaxKB
		  - * ç®€ä»‹ï¼šMaxKB æ˜¯ä¸€æ¬¾åŸºäº LLM å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿã€‚MaxKB = Max Knowledge Baseï¼Œæ—¨åœ¨æˆä¸ºä¼ä¸šçš„æœ€å¼ºå¤§è„‘ã€‚
		  - * ç‰¹æ€§ï¼šå¼€ç®±å³ç”¨ï¼Œæ”¯æŒç›´æ¥ä¸Šä¼ æ–‡æ¡£ã€è‡ªåŠ¨çˆ¬å–åœ¨çº¿æ–‡æ¡£ï¼›æ”¯æŒé›¶ç¼–ç å¿«é€ŸåµŒå…¥åˆ°ç¬¬ä¸‰æ–¹ä¸šåŠ¡ç³»ç»Ÿï¼›æ”¯æŒå¯¹æ¥ä¸»æµçš„å¤§æ¨¡å‹ï¼ŒåŒ…æ‹¬ Ollama æœ¬åœ°ç§æœ‰å¤§æ¨¡å‹ä»¥åŠAPIè°ƒç”¨
		  - * æ¶æ„ï¼š å‰ç«¯ï¼šVue.js åç«¯ï¼šPython / Django LangChainï¼šLangChain å‘é‡æ•°æ®åº“ï¼šPostgreSQL / pgvector
		  - å¤§æ¨¡å‹ï¼šAzure OpenAIã€OpenAIã€ç™¾åº¦åƒå¸†å¤§æ¨¡å‹ã€Ollamaã€é€šä¹‰åƒé—®ã€Kimiã€æ™ºè°± AIã€è®¯é£æ˜Ÿç«
		  - * ç¡¬ä»¶è¦æ±‚ï¼š
		  - æ“ä½œç³»ç»Ÿï¼šUbuntu 22.04 / CentOS 7 64 ä½ç³»ç»Ÿ CPU/å†…å­˜ï¼š æ¨è 2C/4GB ä»¥ä¸Š
		  - ç£ç›˜ç©ºé—´ï¼š100GB
		  -
		  -
		  - ## [[é˜…è¯»æ¸…å•]]
		  - å°é¢:: 1
		  ä¹¦å:: æˆ˜äº‰ä¸å’Œå¹³
		  ä½œè€…:: ä¿„å›½äºº
		  çŠ¶æ€:: å¾…è¯»
		  å¼€å§‹æ—¶é—´::  [[Aug 25th, 2024]] 
		  ç»“æŸæ—¶é—´::  [[Aug 29th, 2024]] 
		  è¯„åˆ†:: 5
		  ç±»å‹:: æˆ˜äº‰
		  å¹´ä»½:: 1960
		  -
		  -
		  - ## [[é˜…è¯»æ¸…å•]]
		  - å°é¢:: 2
		  ä¹¦å:: æªç‚® æˆ˜äº‰ä¸ç»†èŒ
		  ä½œè€…:: ç¾å›½äºº
		  çŠ¶æ€:: æœªè¯»
		  å¼€å§‹æ—¶é—´::  [[Aug 23rd, 2024]] 
		  ç»“æŸæ—¶é—´::  [[Aug 25th, 2024]] 
		  è¯„åˆ†:: 7
		  ç±»å‹:: æ”¿è®º
		  å¹´ä»½:: 1950
		  -
		  -
		  - {{query (and [[é˜…è¯»æ¸…å•]] (property :ä¹¦å) (property :ä½œè€…) (property :å°é¢))}}
		  query-table:: true
		  -
		  - /ca
		  - ```calc
		  1+1
		  1/2
		  1/3
		  2*8
		  3^3
		  sin(45)
		  
		  ```
			- > Hugging Face çš„ Open LLM Leaderboard [â¤´ï¸](https://omnivore.app/me/qwen-2-qwen-2-qwen-2-csdn-1917d392cab#dff3c760-6d49-4b22-a724-ecc3fa516f1f)
-
-
-
-
-
-
-
-
-
-